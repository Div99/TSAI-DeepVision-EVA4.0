{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOEwyNPXSNc9KIiIh8DqvzO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satyajitghana/TSAI-DeepVision-EVA4.0/blob/master/07_AdvancedConvolution/AdvancedConvolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRZXpf_DpzgA",
        "colab_type": "text"
      },
      "source": [
        "## Clone the PySodium Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNw8ZeBOFXau",
        "colab_type": "code",
        "outputId": "bbaafed2-5caf-41af-9c46-418f5733e2e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/satyajitghana/TSAI-DeepVision-EVA4.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'TSAI-DeepVision-EVA4.0'...\n",
            "remote: Enumerating objects: 137, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/137)\u001b[K\rremote: Counting objects:   1% (2/137)\u001b[K\rremote: Counting objects:   2% (3/137)\u001b[K\rremote: Counting objects:   3% (5/137)\u001b[K\rremote: Counting objects:   4% (6/137)\u001b[K\rremote: Counting objects:   5% (7/137)\u001b[K\rremote: Counting objects:   6% (9/137)\u001b[K\rremote: Counting objects:   7% (10/137)\u001b[K\rremote: Counting objects:   8% (11/137)\u001b[K\rremote: Counting objects:   9% (13/137)\u001b[K\rremote: Counting objects:  10% (14/137)\u001b[K\rremote: Counting objects:  11% (16/137)\u001b[K\rremote: Counting objects:  12% (17/137)\u001b[K\rremote: Counting objects:  13% (18/137)\u001b[K\rremote: Counting objects:  14% (20/137)\u001b[K\rremote: Counting objects:  15% (21/137)\u001b[K\rremote: Counting objects:  16% (22/137)\u001b[K\rremote: Counting objects:  17% (24/137)\u001b[K\rremote: Counting objects:  18% (25/137)\u001b[K\rremote: Counting objects:  19% (27/137)\u001b[K\rremote: Counting objects:  20% (28/137)\u001b[K\rremote: Counting objects:  21% (29/137)\u001b[K\rremote: Counting objects:  22% (31/137)\u001b[K\rremote: Counting objects:  23% (32/137)\u001b[K\rremote: Counting objects:  24% (33/137)\u001b[K\rremote: Counting objects:  25% (35/137)\u001b[K\rremote: Counting objects:  26% (36/137)\u001b[K\rremote: Counting objects:  27% (37/137)\u001b[K\rremote: Counting objects:  28% (39/137)\u001b[K\rremote: Counting objects:  29% (40/137)\u001b[K\rremote: Counting objects:  30% (42/137)\u001b[K\rremote: Counting objects:  31% (43/137)\u001b[K\rremote: Counting objects:  32% (44/137)\u001b[K\rremote: Counting objects:  33% (46/137)\u001b[K\rremote: Counting objects:  34% (47/137)\u001b[K\rremote: Counting objects:  35% (48/137)\u001b[K\rremote: Counting objects:  36% (50/137)\u001b[K\rremote: Counting objects:  37% (51/137)\u001b[K\rremote: Counting objects:  38% (53/137)\u001b[K\rremote: Counting objects:  39% (54/137)\u001b[K\rremote: Counting objects:  40% (55/137)\u001b[K\rremote: Counting objects:  41% (57/137)\u001b[K\rremote: Counting objects:  42% (58/137)\u001b[K\rremote: Counting objects:  43% (59/137)\u001b[K\rremote: Counting objects:  44% (61/137)\u001b[K\rremote: Counting objects:  45% (62/137)\u001b[K\rremote: Counting objects:  46% (64/137)\u001b[K\rremote: Counting objects:  47% (65/137)\u001b[K\rremote: Counting objects:  48% (66/137)\u001b[K\rremote: Counting objects:  49% (68/137)\u001b[K\rremote: Counting objects:  50% (69/137)\u001b[K\rremote: Counting objects:  51% (70/137)\u001b[K\rremote: Counting objects:  52% (72/137)\u001b[K\rremote: Counting objects:  53% (73/137)\u001b[K\rremote: Counting objects:  54% (74/137)\u001b[K\rremote: Counting objects:  55% (76/137)\u001b[K\rremote: Counting objects:  56% (77/137)\u001b[K\rremote: Counting objects:  57% (79/137)\u001b[K\rremote: Counting objects:  58% (80/137)\u001b[K\rremote: Counting objects:  59% (81/137)\u001b[K\rremote: Counting objects:  60% (83/137)\u001b[K\rremote: Counting objects:  61% (84/137)\u001b[K\rremote: Counting objects:  62% (85/137)\u001b[K\rremote: Counting objects:  63% (87/137)\u001b[K\rremote: Counting objects:  64% (88/137)\u001b[K\rremote: Counting objects:  65% (90/137)\u001b[K\rremote: Counting objects:  66% (91/137)\u001b[K\rremote: Counting objects:  67% (92/137)\u001b[K\rremote: Counting objects:  68% (94/137)\u001b[K\rremote: Counting objects:  69% (95/137)\u001b[K\rremote: Counting objects:  70% (96/137)\u001b[K\rremote: Counting objects:  71% (98/137)\u001b[K\rremote: Counting objects:  72% (99/137)\u001b[K\rremote: Counting objects:  73% (101/137)\u001b[K\rremote: Counting objects:  74% (102/137)\u001b[K\rremote: Counting objects:  75% (103/137)\u001b[K\rremote: Counting objects:  76% (105/137)\u001b[K\rremote: Counting objects:  77% (106/137)\u001b[K\rremote: Counting objects:  78% (107/137)\u001b[K\rremote: Counting objects:  79% (109/137)\u001b[K\rremote: Counting objects:  80% (110/137)\u001b[K\rremote: Counting objects:  81% (111/137)\u001b[K\rremote: Counting objects:  82% (113/137)\u001b[K\rremote: Counting objects:  83% (114/137)\u001b[K\rremote: Counting objects:  84% (116/137)\u001b[K\rremote: Counting objects:  85% (117/137)\u001b[K\rremote: Counting objects:  86% (118/137)\u001b[K\rremote: Counting objects:  87% (120/137)\u001b[K\rremote: Counting objects:  88% (121/137)\u001b[K\rremote: Counting objects:  89% (122/137)\u001b[K\rremote: Counting objects:  90% (124/137)\u001b[K\rremote: Counting objects:  91% (125/137)\u001b[K\rremote: Counting objects:  92% (127/137)\u001b[K\rremote: Counting objects:  93% (128/137)\u001b[K\rremote: Counting objects:  94% (129/137)\u001b[K\rremote: Counting objects:  95% (131/137)\u001b[K\rremote: Counting objects:  96% (132/137)\u001b[K\rremote: Counting objects:  97% (133/137)\u001b[K\rremote: Counting objects:  98% (135/137)\u001b[K\rremote: Counting objects:  99% (136/137)\u001b[K\rremote: Counting objects: 100% (137/137)\u001b[K\rremote: Counting objects: 100% (137/137), done.\u001b[K\n",
            "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
            "remote: Total 418 (delta 49), reused 124 (delta 36), pack-reused 281\u001b[K\n",
            "Receiving objects: 100% (418/418), 40.21 MiB | 22.40 MiB/s, done.\n",
            "Resolving deltas: 100% (187/187), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQZJpbK0F1dA",
        "colab_type": "code",
        "outputId": "90bd4de2-60cb-4e3a-9664-d2c304e7fae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd TSAI-DeepVision-EVA4.0/07_AdvancedConvolution/PySodium/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/TSAI-DeepVision-EVA4.0/07_AdvancedConvolution/PySodium\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3z7C9OEDp8iO",
        "colab_type": "text"
      },
      "source": [
        "# Run the CIFAR10 Model for 50 Epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEIiVR7hqXAR",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "Params : 344,032\n",
        "Max Test Accuracy: 80.71\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haCZRg3XF9a4",
        "colab_type": "code",
        "outputId": "74959bab-176a-4ed9-d475-07e6325ddb25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python main.py --config=experiments/cifar10_config.yml --device=0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2020-03-03 22:54:18,098 - sodium.__main__ ] INFO: Training: {'name': 'CIFAR10_MyNet', 'save_dir': 'saved/', 'seed': 1, 'target_device': 0, 'arch': {'type': 'CIFAR10Model', 'args': {}}, 'augmentation': {'type': 'CIFAR10Transforms', 'args': {}}, 'data_loader': {'type': 'CIFAR10DataLoader', 'args': {'batch_size': 64, 'data_dir': 'data/', 'nworkers': 4, 'shuffle': True}}, 'loss': 'nll_loss', 'optimizer': {'type': 'SGD', 'args': {'lr': 0.008, 'momentum': 0.95}}, 'training': {'epochs': 50}}\n",
            "[ 2020-03-03 22:54:18,098 - sodium.__main__ ] INFO: Building: sodium.model.model.CIFAR10Model\n",
            "[ 2020-03-03 22:54:18,194 - sodium.__main__ ] INFO: Using device 0 of available devices [0]\n",
            "[ 2020-03-03 22:54:27,123 - sodium.__main__ ] INFO: Building: torch.optim.SGD\n",
            "[ 2020-03-03 22:54:27,123 - sodium.__main__ ] INFO: Building: sodium.data_loader.augmentation.CIFAR10Transforms\n",
            "[ 2020-03-03 22:54:27,123 - sodium.__main__ ] INFO: Building: sodium.data_loader.data_loaders.CIFAR10DataLoader\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n",
            "170500096it [00:03, 43013895.17it/s]                   \n",
            "Extracting data/cifar-10-python.tar.gz to data/\n",
            "Files already downloaded and verified\n",
            "[ 2020-03-03 22:54:34,413 - sodium.__main__ ] INFO: Getting loss function handle\n",
            "[ 2020-03-03 22:54:34,414 - sodium.__main__ ] INFO: Initializing trainer\n",
            "[ 2020-03-03 22:54:34,414 - sodium.sodium.base.base_trainer ] INFO: Starting training ...\n",
            "[ 2020-03-03 22:54:34,414 - sodium.sodium.base.base_trainer ] INFO: Training the model for 50 epochs\n",
            "Training Epoch: 1\n",
            "epoch=1 loss=1.3414895535 batch_id=781: 100% 782/782 [00:19<00:00, 39.28it/s]\n",
            "Test set: Accuracy: 27.65\n",
            "Training Epoch: 2\n",
            "epoch=2 loss=1.0419018269 batch_id=781: 100% 782/782 [00:19<00:00, 39.30it/s]\n",
            "Test set: Accuracy: 51.66\n",
            "Training Epoch: 3\n",
            "epoch=3 loss=1.1499898434 batch_id=781: 100% 782/782 [00:19<00:00, 39.43it/s]\n",
            "Test set: Accuracy: 49.23\n",
            "Training Epoch: 4\n",
            "epoch=4 loss=0.4848939180 batch_id=781: 100% 782/782 [00:19<00:00, 40.20it/s]\n",
            "Test set: Accuracy: 50.67\n",
            "Training Epoch: 5\n",
            "epoch=5 loss=0.4917156398 batch_id=781: 100% 782/782 [00:19<00:00, 40.66it/s]\n",
            "Test set: Accuracy: 63.65\n",
            "Training Epoch: 6\n",
            "epoch=6 loss=1.1476051807 batch_id=781: 100% 782/782 [00:19<00:00, 40.31it/s]\n",
            "Test set: Accuracy: 60.48\n",
            "Training Epoch: 7\n",
            "epoch=7 loss=0.6393318176 batch_id=781: 100% 782/782 [00:19<00:00, 40.29it/s]\n",
            "Test set: Accuracy: 66.04\n",
            "Training Epoch: 8\n",
            "epoch=8 loss=0.8483913541 batch_id=781: 100% 782/782 [00:19<00:00, 42.75it/s]\n",
            "Test set: Accuracy: 66.08\n",
            "Training Epoch: 9\n",
            "epoch=9 loss=1.2202727795 batch_id=781: 100% 782/782 [00:19<00:00, 40.29it/s]\n",
            "Test set: Accuracy: 73.16\n",
            "Training Epoch: 10\n",
            "epoch=10 loss=0.5469111204 batch_id=781: 100% 782/782 [00:19<00:00, 43.03it/s]\n",
            "Test set: Accuracy: 70.84\n",
            "Training Epoch: 11\n",
            "epoch=11 loss=0.3808762133 batch_id=781: 100% 782/782 [00:19<00:00, 43.52it/s]\n",
            "Test set: Accuracy: 68.72\n",
            "Training Epoch: 12\n",
            "epoch=12 loss=0.3643867671 batch_id=781: 100% 782/782 [00:19<00:00, 42.84it/s]\n",
            "Test set: Accuracy: 71.09\n",
            "Training Epoch: 13\n",
            "epoch=13 loss=0.3913764656 batch_id=781: 100% 782/782 [00:19<00:00, 40.18it/s]\n",
            "Test set: Accuracy: 70.68\n",
            "Training Epoch: 14\n",
            "epoch=14 loss=0.6568995714 batch_id=781: 100% 782/782 [00:19<00:00, 40.30it/s]\n",
            "Test set: Accuracy: 73.43\n",
            "Training Epoch: 15\n",
            "epoch=15 loss=0.9497343898 batch_id=781: 100% 782/782 [00:19<00:00, 40.21it/s]\n",
            "Test set: Accuracy: 70.06\n",
            "Training Epoch: 16\n",
            "epoch=16 loss=0.6844101548 batch_id=781: 100% 782/782 [00:19<00:00, 40.03it/s]\n",
            "Test set: Accuracy: 72.91\n",
            "Training Epoch: 17\n",
            "epoch=17 loss=1.0270491838 batch_id=781: 100% 782/782 [00:19<00:00, 40.25it/s]\n",
            "Test set: Accuracy: 72.96\n",
            "Training Epoch: 18\n",
            "epoch=18 loss=0.5021054745 batch_id=781: 100% 782/782 [00:19<00:00, 40.50it/s]\n",
            "Test set: Accuracy: 75.45\n",
            "Training Epoch: 19\n",
            "epoch=19 loss=0.4757013917 batch_id=781: 100% 782/782 [00:19<00:00, 39.97it/s]\n",
            "Test set: Accuracy: 77.69\n",
            "Training Epoch: 20\n",
            "epoch=20 loss=1.1615256071 batch_id=781: 100% 782/782 [00:19<00:00, 42.96it/s]\n",
            "Test set: Accuracy: 73.01\n",
            "Training Epoch: 21\n",
            "epoch=21 loss=0.5261611938 batch_id=781: 100% 782/782 [00:19<00:00, 42.95it/s]\n",
            "Test set: Accuracy: 78.16\n",
            "Training Epoch: 22\n",
            "epoch=22 loss=0.3504853249 batch_id=781: 100% 782/782 [00:19<00:00, 40.33it/s]\n",
            "Test set: Accuracy: 75.55\n",
            "Training Epoch: 23\n",
            "epoch=23 loss=1.3858498335 batch_id=781: 100% 782/782 [00:19<00:00, 43.55it/s]\n",
            "Test set: Accuracy: 74.29\n",
            "Training Epoch: 24\n",
            "epoch=24 loss=0.4206817150 batch_id=781: 100% 782/782 [00:19<00:00, 43.64it/s]\n",
            "Test set: Accuracy: 75.75\n",
            "Training Epoch: 25\n",
            "epoch=25 loss=1.0595155954 batch_id=781: 100% 782/782 [00:19<00:00, 40.20it/s]\n",
            "Test set: Accuracy: 78.71\n",
            "Training Epoch: 26\n",
            "epoch=26 loss=0.8333079219 batch_id=781: 100% 782/782 [00:19<00:00, 40.18it/s]\n",
            "Test set: Accuracy: 76.64\n",
            "Training Epoch: 27\n",
            "epoch=27 loss=0.7093594074 batch_id=781: 100% 782/782 [00:19<00:00, 43.66it/s]\n",
            "Test set: Accuracy: 76.52\n",
            "Training Epoch: 28\n",
            "epoch=28 loss=0.2618134022 batch_id=781: 100% 782/782 [00:19<00:00, 40.45it/s]\n",
            "Test set: Accuracy: 74.24\n",
            "Training Epoch: 29\n",
            "epoch=29 loss=0.6720687747 batch_id=781: 100% 782/782 [00:19<00:00, 43.60it/s]\n",
            "Test set: Accuracy: 77.55\n",
            "Training Epoch: 30\n",
            "epoch=30 loss=0.5437931418 batch_id=781: 100% 782/782 [00:19<00:00, 40.31it/s]\n",
            "Test set: Accuracy: 75.38\n",
            "Training Epoch: 31\n",
            "epoch=31 loss=0.8022992015 batch_id=781: 100% 782/782 [00:18<00:00, 41.30it/s]\n",
            "Test set: Accuracy: 75.74\n",
            "Training Epoch: 32\n",
            "epoch=32 loss=0.3977631629 batch_id=781: 100% 782/782 [00:19<00:00, 40.65it/s]\n",
            "Test set: Accuracy: 75.4\n",
            "Training Epoch: 33\n",
            "epoch=33 loss=0.4650067091 batch_id=781: 100% 782/782 [00:19<00:00, 40.41it/s]\n",
            "Test set: Accuracy: 80.09\n",
            "Training Epoch: 34\n",
            "epoch=34 loss=1.0284581184 batch_id=781: 100% 782/782 [00:19<00:00, 40.89it/s]\n",
            "Test set: Accuracy: 79.53\n",
            "Training Epoch: 35\n",
            "epoch=35 loss=0.4025305510 batch_id=781: 100% 782/782 [00:19<00:00, 43.57it/s]\n",
            "Test set: Accuracy: 76.41\n",
            "Training Epoch: 36\n",
            "epoch=36 loss=0.5547651052 batch_id=781: 100% 782/782 [00:19<00:00, 40.32it/s]\n",
            "Test set: Accuracy: 78.87\n",
            "Training Epoch: 37\n",
            "epoch=37 loss=0.8995084763 batch_id=781: 100% 782/782 [00:19<00:00, 40.71it/s]\n",
            "Test set: Accuracy: 75.74\n",
            "Training Epoch: 38\n",
            "epoch=38 loss=0.1948822290 batch_id=781: 100% 782/782 [00:19<00:00, 41.08it/s]\n",
            "Test set: Accuracy: 79.85\n",
            "Training Epoch: 39\n",
            "epoch=39 loss=0.3655758798 batch_id=781: 100% 782/782 [00:19<00:00, 40.77it/s]\n",
            "Test set: Accuracy: 78.95\n",
            "Training Epoch: 40\n",
            "epoch=40 loss=0.4775102735 batch_id=781: 100% 782/782 [00:19<00:00, 40.74it/s]\n",
            "Test set: Accuracy: 77.74\n",
            "Training Epoch: 41\n",
            "epoch=41 loss=0.1895846128 batch_id=781: 100% 782/782 [00:18<00:00, 41.16it/s]\n",
            "Test set: Accuracy: 78.5\n",
            "Training Epoch: 42\n",
            "epoch=42 loss=0.2660197020 batch_id=781: 100% 782/782 [00:19<00:00, 40.95it/s]\n",
            "Test set: Accuracy: 79.73\n",
            "Training Epoch: 43\n",
            "epoch=43 loss=0.2093307078 batch_id=781: 100% 782/782 [00:19<00:00, 44.06it/s]\n",
            "Test set: Accuracy: 78.7\n",
            "Training Epoch: 44\n",
            "epoch=44 loss=1.0514261723 batch_id=781: 100% 782/782 [00:19<00:00, 40.69it/s]\n",
            "Test set: Accuracy: 79.0\n",
            "Training Epoch: 45\n",
            "epoch=45 loss=0.9223704934 batch_id=781: 100% 782/782 [00:19<00:00, 40.09it/s]\n",
            "Test set: Accuracy: 79.77\n",
            "Training Epoch: 46\n",
            "epoch=46 loss=0.3726564944 batch_id=781: 100% 782/782 [00:19<00:00, 40.55it/s]\n",
            "Test set: Accuracy: 80.14\n",
            "Training Epoch: 47\n",
            "epoch=47 loss=0.0828369260 batch_id=781: 100% 782/782 [00:19<00:00, 40.51it/s]\n",
            "Test set: Accuracy: 80.71\n",
            "Training Epoch: 48\n",
            "epoch=48 loss=0.0597159266 batch_id=781: 100% 782/782 [00:19<00:00, 40.38it/s]\n",
            "Test set: Accuracy: 79.78\n",
            "Training Epoch: 49\n",
            "epoch=49 loss=0.2069731951 batch_id=781: 100% 782/782 [00:19<00:00, 40.20it/s]\n",
            "Test set: Accuracy: 79.82\n",
            "Training Epoch: 50\n",
            "epoch=50 loss=0.1346652508 batch_id=781: 100% 782/782 [00:19<00:00, 40.50it/s]\n",
            "Test set: Accuracy: 79.42\n",
            "[ 2020-03-03 23:12:26,986 - sodium.__main__ ] INFO: Finished!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYVdHg0GpxM0",
        "colab_type": "text"
      },
      "source": [
        "# The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkE2sBeHqNFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvW1CiMDHb5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CIFAR10Model(nn.Module):\n",
        "\n",
        "    def __init__(self, dropout_value=0.25):\n",
        "\n",
        "        self.dropout_value = dropout_value  # dropout value\n",
        "\n",
        "        super(CIFAR10Model, self).__init__()\n",
        "\n",
        "        # Input Block\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=32,\n",
        "                      kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(self.dropout_value)\n",
        "        )  # output_size = 32\n",
        "\n",
        "        # CONVOLUTION BLOCK 1\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64,\n",
        "                      kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(self.dropout_value)\n",
        "        )  # output_size = 32\n",
        "\n",
        "        # TRANSITION BLOCK 1\n",
        "        self.convblock3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=32,\n",
        "                      kernel_size=(1, 1), padding=0, bias=False),\n",
        "        )  # output_size = 32\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)  # output_size = 16\n",
        "\n",
        "        # CONVOLUTION BLOCK 2\n",
        "        # DEPTHWISE CONVOLUTION AND POINTWISE CONVOLUTION\n",
        "        self.depthwise1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64,\n",
        "                      kernel_size=(3, 3), padding=0, groups=32, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(self.dropout_value)\n",
        "        )  # output_size = 16\n",
        "        self.convblock4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128,\n",
        "                      kernel_size=(1, 1), padding=0, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(self.dropout_value)\n",
        "        )  # output_size = 16\n",
        "\n",
        "        # TRANSITION BLOCK 2\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)  # output_size = 8\n",
        "\n",
        "        # CONVOLUTION BLOCK 3\n",
        "        self.convblock5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=128,\n",
        "                      kernel_size=(3, 3), padding=4, dilation=2, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(self.dropout_value)\n",
        "        )  # output_size = 11\n",
        "        self.convblock6 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=128,\n",
        "                      kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(self.dropout_value)\n",
        "        )  # output_size = 11\n",
        "\n",
        "        # TRANSITION BLOCK 3\n",
        "        self.pool3 = nn.MaxPool2d(2, 2)  # output_size = 5\n",
        "\n",
        "        # OUTPUT BLOCK\n",
        "        self.gap = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=5)\n",
        "        )  # output_size = 1\n",
        "\n",
        "        self.convblock7 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=128,\n",
        "                      kernel_size=(1, 1), padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Dropout(self.dropout_value)\n",
        "        )\n",
        "\n",
        "        self.convblock8 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=10,\n",
        "                      kernel_size=(1, 1), padding=0, bias=False),\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(self.dropout_value)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convblock1(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.convblock3(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.depthwise1(x)\n",
        "        x = self.convblock4(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.convblock5(x)\n",
        "        x = self.convblock6(x)\n",
        "        x = self.pool3(x)\n",
        "        x = self.gap(x)\n",
        "        x = self.convblock7(x)\n",
        "        x = self.convblock8(x)\n",
        "\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x, dim=-1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gv7U_sPLqDrl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "outputId": "31a3baab-37de-423e-9c46-bacc0801517e"
      },
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "model = CIFAR10Model().to(device)\n",
        "summary(model, input_size=(3, 32, 32))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n",
            "cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 32, 32]             864\n",
            "       BatchNorm2d-2           [-1, 32, 32, 32]              64\n",
            "              ReLU-3           [-1, 32, 32, 32]               0\n",
            "           Dropout-4           [-1, 32, 32, 32]               0\n",
            "            Conv2d-5           [-1, 64, 32, 32]          18,432\n",
            "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
            "              ReLU-7           [-1, 64, 32, 32]               0\n",
            "           Dropout-8           [-1, 64, 32, 32]               0\n",
            "            Conv2d-9           [-1, 32, 32, 32]           2,048\n",
            "        MaxPool2d-10           [-1, 32, 16, 16]               0\n",
            "           Conv2d-11           [-1, 64, 14, 14]             576\n",
            "      BatchNorm2d-12           [-1, 64, 14, 14]             128\n",
            "             ReLU-13           [-1, 64, 14, 14]               0\n",
            "          Dropout-14           [-1, 64, 14, 14]               0\n",
            "           Conv2d-15          [-1, 128, 14, 14]           8,192\n",
            "      BatchNorm2d-16          [-1, 128, 14, 14]             256\n",
            "             ReLU-17          [-1, 128, 14, 14]               0\n",
            "          Dropout-18          [-1, 128, 14, 14]               0\n",
            "        MaxPool2d-19            [-1, 128, 7, 7]               0\n",
            "           Conv2d-20          [-1, 128, 11, 11]         147,456\n",
            "      BatchNorm2d-21          [-1, 128, 11, 11]             256\n",
            "             ReLU-22          [-1, 128, 11, 11]               0\n",
            "          Dropout-23          [-1, 128, 11, 11]               0\n",
            "           Conv2d-24          [-1, 128, 11, 11]         147,456\n",
            "      BatchNorm2d-25          [-1, 128, 11, 11]             256\n",
            "             ReLU-26          [-1, 128, 11, 11]               0\n",
            "          Dropout-27          [-1, 128, 11, 11]               0\n",
            "        MaxPool2d-28            [-1, 128, 5, 5]               0\n",
            "        AvgPool2d-29            [-1, 128, 1, 1]               0\n",
            "           Conv2d-30            [-1, 128, 1, 1]          16,384\n",
            "             ReLU-31            [-1, 128, 1, 1]               0\n",
            "      BatchNorm2d-32            [-1, 128, 1, 1]             256\n",
            "          Dropout-33            [-1, 128, 1, 1]               0\n",
            "           Conv2d-34             [-1, 10, 1, 1]           1,280\n",
            "================================================================\n",
            "Total params: 344,032\n",
            "Trainable params: 344,032\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.48\n",
            "Params size (MB): 1.31\n",
            "Estimated Total Size (MB): 6.81\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VUj4PCGrChb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}